{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DATA PREPROCESSING",
   "id": "faa7f8a6a4ed2d8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:36:05.058763846Z",
     "start_time": "2026-01-13T16:36:05.043844327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# DROP NANS\n",
    "file_name = 'dataset_ultimate_plus.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "df_cleaned.to_csv('cleaned_dataset_ultimate_plus.csv', index=False)\n",
    "\n",
    "print(f\"Removed: {len(df) - len(df_cleaned)}\")\n",
    "\n"
   ],
   "id": "b2ffe3b35317614",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:25:57.411730922Z",
     "start_time": "2026-01-14T01:25:25.107882181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# CONFIGURATION\n",
    "input_file = 'cleaned_dataset_ultimate_plus.csv'\n",
    "# target_map = 'de_mirage'\n",
    "# target_map = 'de_dust2'\n",
    "# target_map = 'de_ancient'\n",
    "# target_map = 'de_nuke'\n",
    "# target_map = 'de_inferno'\n",
    "# target_map = 'de_train'\n",
    "# target_map = 'de_overpass'\n",
    "target_map = 'de_anubis'\n",
    "\n",
    "train_ready_file = f'output_{target_map}.csv'\n",
    "metadata_file = f'meta_{target_map}.csv'\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"File {input_file} not found!\")\n",
    "else:\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    df = df[df['map'] == target_map].copy()\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'winner': 'target',\n",
    "    })\n",
    "\n",
    "    meta_columns = ['match_id', 'team1_score', 'team2_score', 'target']\n",
    "    meta_columns = [c for c in meta_columns if c in df.columns]\n",
    "\n",
    "    df_meta = df[meta_columns].copy()\n",
    "    df_meta.to_csv(metadata_file, index=False)\n",
    "\n",
    "    cols_to_drop = ['match_id', 'team1_score', 'team2_score', 'map']\n",
    "    df_train = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "    df_train.to_csv(train_ready_file, index=False)\n",
    "\n",
    "    print(f\"1. Train (X, y): '{train_ready_file}' (Columns: {len(df_train.columns)})\")\n",
    "    print(f\"2. Meta (Score, ID): '{metadata_file}'\")\n",
    "    print(f\"Total matches: {len(df)}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Train (X, y): 'output_de_anubis.csv' (Columns: 441)\n",
      "2. Meta (Score, ID): 'meta_de_anubis.csv'\n",
      "Total matches: 142408\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MODEL",
   "id": "c3f89a0f80e243a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:26:51.725639985Z",
     "start_time": "2026-01-14T01:26:49.582036506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FaceitPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        player_embeddings = self.phi(x)\n",
    "\n",
    "        t1_sum = player_embeddings[:, :5, :].sum(dim=1)\n",
    "        t2_sum = player_embeddings[:, 5:, :].sum(dim=1)\n",
    "\n",
    "        t1_strength = self.rho(t1_sum)\n",
    "        t2_strength = self.rho(t2_sum)\n",
    "\n",
    "        return torch.sigmoid(t1_strength - t2_strength)"
   ],
   "id": "a6fa43687240d01c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TRAIN MODEL",
   "id": "68bc8a118951c0e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:27:26.621212410Z",
     "start_time": "2026-01-14T01:26:51.726473699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOAD DATA\n",
    "df_train = pd.read_csv(f'output_{target_map}.csv')\n",
    "df_meta = pd.read_csv(f'meta_{target_map}.csv')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "def calculate_weights(df):\n",
    "    s1 = df['team1_score'].astype(int)\n",
    "    s2 = df['team2_score'].astype(int)\n",
    "\n",
    "    diff = abs(s1 - s2)\n",
    "\n",
    "    weights = 0.2 + 0.8 * (diff / 13.0)\n",
    "    return weights.values\n",
    "\n",
    "\n",
    "X = df_train.drop(columns=['target']).values\n",
    "y = df_train['target'].values\n",
    "weights = calculate_weights(df_meta)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "num_players = 10\n",
    "num_features_per_player = X_scaled.shape[1] // num_players\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32).view(-1, num_players, num_features_per_player)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X_tensor, y_tensor, weights_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train, w_train), batch_size=256, shuffle=True)\n",
    "\n",
    "model = FaceitPredictor(num_features_per_player).to(device)\n",
    "criterion = nn.BCELoss(reduction='none').to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "summary(model, input_size=(32, 10, num_features_per_player), device=device, verbose=1)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y, batch_w in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_w = batch_w.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "\n",
    "        raw_loss = criterion(output, batch_y)\n",
    "        weighted_loss = raw_loss * batch_w\n",
    "\n",
    "        loss = weighted_loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Weighted Loss: {total_loss / len(train_loader):.4f}\")\n"
   ],
   "id": "6d26cc9c96c98089",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "FaceitPredictor                          [32, 1]                   --\n",
      "├─Sequential: 1-1                        [32, 10, 32]              --\n",
      "│    └─Linear: 2-1                       [32, 10, 32]              1,440\n",
      "│    └─ReLU: 2-2                         [32, 10, 32]              --\n",
      "│    └─Dropout: 2-3                      [32, 10, 32]              --\n",
      "│    └─Linear: 2-4                       [32, 10, 32]              1,056\n",
      "│    └─ReLU: 2-5                         [32, 10, 32]              --\n",
      "├─Sequential: 1-2                        [32, 1]                   --\n",
      "│    └─Linear: 2-6                       [32, 32]                  1,056\n",
      "│    └─ReLU: 2-7                         [32, 32]                  --\n",
      "│    └─Dropout: 2-8                      [32, 32]                  --\n",
      "│    └─Linear: 2-9                       [32, 1]                   33\n",
      "├─Sequential: 1-3                        [32, 1]                   (recursive)\n",
      "│    └─Linear: 2-10                      [32, 32]                  (recursive)\n",
      "│    └─ReLU: 2-11                        [32, 32]                  --\n",
      "│    └─Dropout: 2-12                     [32, 32]                  --\n",
      "│    └─Linear: 2-13                      [32, 1]                   (recursive)\n",
      "==========================================================================================\n",
      "Total params: 3,585\n",
      "Trainable params: 3,585\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.18\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.25\n",
      "==========================================================================================\n",
      "Epoch 1, Weighted Loss: 0.3429\n",
      "Epoch 2, Weighted Loss: 0.3390\n",
      "Epoch 3, Weighted Loss: 0.3373\n",
      "Epoch 4, Weighted Loss: 0.3364\n",
      "Epoch 5, Weighted Loss: 0.3360\n",
      "Epoch 6, Weighted Loss: 0.3355\n",
      "Epoch 7, Weighted Loss: 0.3347\n",
      "Epoch 8, Weighted Loss: 0.3345\n",
      "Epoch 9, Weighted Loss: 0.3341\n",
      "Epoch 10, Weighted Loss: 0.3337\n",
      "Epoch 11, Weighted Loss: 0.3327\n",
      "Epoch 12, Weighted Loss: 0.3327\n",
      "Epoch 13, Weighted Loss: 0.3322\n",
      "Epoch 14, Weighted Loss: 0.3322\n",
      "Epoch 15, Weighted Loss: 0.3321\n",
      "Epoch 16, Weighted Loss: 0.3321\n",
      "Epoch 17, Weighted Loss: 0.3317\n",
      "Epoch 18, Weighted Loss: 0.3319\n",
      "Epoch 19, Weighted Loss: 0.3314\n",
      "Epoch 20, Weighted Loss: 0.3314\n",
      "Epoch 21, Weighted Loss: 0.3313\n",
      "Epoch 22, Weighted Loss: 0.3310\n",
      "Epoch 23, Weighted Loss: 0.3310\n",
      "Epoch 24, Weighted Loss: 0.3303\n",
      "Epoch 25, Weighted Loss: 0.3306\n",
      "Epoch 26, Weighted Loss: 0.3304\n",
      "Epoch 27, Weighted Loss: 0.3299\n",
      "Epoch 28, Weighted Loss: 0.3302\n",
      "Epoch 29, Weighted Loss: 0.3300\n",
      "Epoch 30, Weighted Loss: 0.3305\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:27:26.916080402Z",
     "start_time": "2026-01-14T01:27:26.673346130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_detailed_results(model, X_tensor, indices, original_df, filename, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(X_tensor.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "    results_df = original_df.iloc[indices].copy()\n",
    "\n",
    "    results_df['predicted_prob_t1'] = probs\n",
    "    results_df['predicted_winner'] = (probs > 0.5).astype(int)\n",
    "\n",
    "    results_df = results_df.rename(columns={'target': 'real_winner_t1'})\n",
    "\n",
    "    final_cols = [\n",
    "        'match_id',\n",
    "        'team1_score',\n",
    "        'team2_score',\n",
    "        'real_winner_t1',\n",
    "        'predicted_prob_t1',\n",
    "        'predicted_winner'\n",
    "    ]\n",
    "\n",
    "    results_df[final_cols].to_csv(filename, index=False)\n",
    "    print(\n",
    "        f\"File {filename} saved. Accuracy: {(results_df['real_winner_t1'] == results_df['predicted_winner']).mean():.4f}\")\n",
    "\n",
    "\n",
    "df_indices = np.arange(len(df_meta))\n",
    "train_idx, test_idx = train_test_split(df_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "save_detailed_results(model, X_train, train_idx, df_meta, f'results_train_{target_map}.csv', device)\n",
    "\n",
    "save_detailed_results(model, X_test, test_idx, df_meta, f'results_test_{target_map}.csv', device)"
   ],
   "id": "ddf32f01716c9566",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File results_train_de_anubis.csv saved. Accuracy: 0.6138\n",
      "File results_test_de_anubis.csv saved. Accuracy: 0.6001\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## EXPORT MODEL",
   "id": "2a9bfedecf27cce6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:27:28.087924593Z",
     "start_time": "2026-01-14T01:27:26.917144075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "dummy_input = torch.randn(1, 10, num_features_per_player).to(device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    f\"model_{target_map}.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=18,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")"
   ],
   "id": "6a0314e11710021",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11221/1225057826.py:3: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `FaceitPredictor([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `FaceitPredictor([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 2 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.1+cu130',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[s77,10,44]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[s77,1]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"phi.0.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"phi.3.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"rho.0.weight\"<FLOAT,[32,32]>{TorchTensor(...)},\n",
       "                %\"rho.0.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"rho.3.weight\"<FLOAT,[1,32]>{TorchTensor(...)},\n",
       "                %\"rho.3.bias\"<FLOAT,[1]>{TorchTensor<FLOAT,[1]>(Parameter containing: tensor([4.9055e-41], device='cuda:0', requires_grad=True), name='rho.3.bias')},\n",
       "                %\"val_0\"<FLOAT,[44,32]>{Tensor(...)},\n",
       "                %\"val_2\"<FLOAT,[32,32]>{Tensor(...)},\n",
       "                %\"val_18\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_18')},\n",
       "                %\"val_22\"<INT64,[1]>{Tensor<INT64,[1]>(array([5]), name='val_22')},\n",
       "                %\"val_26\"<INT64,[1]>{Tensor<INT64,[1]>(array([1]), name='val_26')},\n",
       "                %\"val_47\"<INT64,[1]>{Tensor<INT64,[1]>(array([9223372036854775807]), name='val_47')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_MatMul_1\n",
       "                  %\"val_1\"<FLOAT,[s77,10,32]> ⬅️ ::MatMul(%\"input\", %\"val_0\"{...})\n",
       "             1 |  # node_linear\n",
       "                  %\"linear\"<FLOAT,[s77,10,32]> ⬅️ ::Add(%\"val_1\", %\"phi.0.bias\"{...})\n",
       "             2 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[s77,10,32]> ⬅️ ::Relu(%\"linear\")\n",
       "             3 |  # node_MatMul_3\n",
       "                  %\"val_3\"<FLOAT,[s77,10,32]> ⬅️ ::MatMul(%\"relu\", %\"val_2\"{...})\n",
       "             4 |  # node_linear_1\n",
       "                  %\"linear_1\"<FLOAT,[s77,10,32]> ⬅️ ::Add(%\"val_3\", %\"phi.3.bias\"{...})\n",
       "             5 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[s77,10,32]> ⬅️ ::Relu(%\"linear_1\")\n",
       "             6 |  # node_slice_2\n",
       "                  %\"slice_2\"<FLOAT,[s77,5,32]> ⬅️ ::Slice(%\"relu_1\", %\"val_18\"{[0]}, %\"val_22\"{[5]}, %\"val_26\"{[1]}, %\"val_26\"{[1]})\n",
       "             7 |  # node_sum_1\n",
       "                  %\"sum_1\"<FLOAT,[s77,32]> ⬅️ ::ReduceSum(%\"slice_2\", %\"val_26\"{[1]}) {noop_with_empty_axes=0, keepdims=0}\n",
       "             8 |  # node_slice_4\n",
       "                  %\"slice_4\"<FLOAT,[s77,5,32]> ⬅️ ::Slice(%\"relu_1\", %\"val_22\"{[5]}, %\"val_47\"{[9223372036854775807]}, %\"val_26\"{[1]}, %\"val_26\"{[1]})\n",
       "             9 |  # node_sum_2\n",
       "                  %\"sum_2\"<FLOAT,[s77,32]> ⬅️ ::ReduceSum(%\"slice_4\", %\"val_26\"{[1]}) {noop_with_empty_axes=0, keepdims=0}\n",
       "            10 |  # node_linear_2\n",
       "                  %\"linear_2\"<FLOAT,[s77,32]> ⬅️ ::Gemm(%\"sum_1\", %\"rho.0.weight\"{...}, %\"rho.0.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            11 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[s77,32]> ⬅️ ::Relu(%\"linear_2\")\n",
       "            12 |  # node_linear_3\n",
       "                  %\"linear_3\"<FLOAT,[s77,1]> ⬅️ ::Gemm(%\"relu_2\", %\"rho.3.weight\"{...}, %\"rho.3.bias\"{[4.905525534061887e-41]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            13 |  # node_linear_4\n",
       "                  %\"linear_4\"<FLOAT,[s77,32]> ⬅️ ::Gemm(%\"sum_2\", %\"rho.0.weight\"{...}, %\"rho.0.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            14 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[s77,32]> ⬅️ ::Relu(%\"linear_4\")\n",
       "            15 |  # node_linear_5\n",
       "                  %\"linear_5\"<FLOAT,[s77,1]> ⬅️ ::Gemm(%\"relu_3\", %\"rho.3.weight\"{...}, %\"rho.3.bias\"{[4.905525534061887e-41]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            16 |  # node_sub_24\n",
       "                  %\"sub_24\"<FLOAT,[s77,1]> ⬅️ ::Sub(%\"linear_3\", %\"linear_5\")\n",
       "            17 |  # node_sigmoid\n",
       "                  %\"output\"<FLOAT,[s77,1]> ⬅️ ::Sigmoid(%\"sub_24\")\n",
       "            return %\"output\"<FLOAT,[s77,1]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_phi_0_weight: \"f32[32, 44]\", p_phi_0_bias: \"f32[32]\", p_phi_3_weight: \"f32[32, 32]\", p_phi_3_bias: \"f32[32]\", p_rho_0_weight: \"f32[32, 32]\", p_rho_0_bias: \"f32[32]\", p_rho_3_weight: \"f32[1, 32]\", p_rho_3_bias: \"f32[1]\", x: \"f32[s77, 10, 44]\"):\n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[s77, 10, 32]\" = torch.ops.aten.linear.default(x, p_phi_0_weight, p_phi_0_bias);  x = p_phi_0_weight = p_phi_0_bias = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[s77, 10, 32]\" = torch.ops.aten.relu.default(linear);  linear = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone: \"f32[s77, 10, 32]\" = torch.ops.aten.clone.default(relu);  relu = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[s77, (10//s77), 32]\" = torch.ops.aten.linear.default(clone, p_phi_3_weight, p_phi_3_bias);  clone = p_phi_3_weight = p_phi_3_bias = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[s77, (10//s77), 32]\" = torch.ops.aten.relu.default(linear_1);  linear_1 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_11221/3356513853.py:31 in forward, code: t1_sum = player_embeddings[:, :5, :].sum(dim=1)\n",
       "                    slice_1: \"f32[s77, (10//s77), 32]\" = torch.ops.aten.slice.Tensor(relu_1, 0, 0, 9223372036854775807)\n",
       "                    slice_2: \"f32[s77, 5, 32]\" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 5);  slice_1 = None\n",
       "                    sum_1: \"f32[s77, 32]\" = torch.ops.aten.sum.dim_IntList(slice_2, [1]);  slice_2 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_11221/3356513853.py:32 in forward, code: t2_sum = player_embeddings[:, 5:, :].sum(dim=1)\n",
       "                    slice_3: \"f32[s77, (10//s77), 32]\" = torch.ops.aten.slice.Tensor(relu_1, 0, 0, 9223372036854775807);  relu_1 = None\n",
       "                    slice_4: \"f32[s77, ((10//s77)) - 5, 32]\" = torch.ops.aten.slice.Tensor(slice_3, 1, 5, 9223372036854775807);  slice_3 = None\n",
       "                    sum_2: \"f32[s77, 32]\" = torch.ops.aten.sum.dim_IntList(slice_4, [1]);  slice_4 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[s77, 32]\" = torch.ops.aten.linear.default(sum_1, p_rho_0_weight, p_rho_0_bias);  sum_1 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[s77, 32]\" = torch.ops.aten.relu.default(linear_2);  linear_2 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_1: \"f32[s77, 32]\" = torch.ops.aten.clone.default(relu_2);  relu_2 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_3: \"f32[s77, 1]\" = torch.ops.aten.linear.default(clone_1, p_rho_3_weight, p_rho_3_bias);  clone_1 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_4: \"f32[s77, 32]\" = torch.ops.aten.linear.default(sum_2, p_rho_0_weight, p_rho_0_bias);  sum_2 = p_rho_0_weight = p_rho_0_bias = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[s77, 32]\" = torch.ops.aten.relu.default(linear_4);  linear_4 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_2: \"f32[s77, 32]\" = torch.ops.aten.clone.default(relu_3);  relu_3 = None\n",
       "            \n",
       "                     # File: /home/blalex/PycharmProjects/FaceitPredictor/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_5: \"f32[s77, 1]\" = torch.ops.aten.linear.default(clone_2, p_rho_3_weight, p_rho_3_bias);  clone_2 = p_rho_3_weight = p_rho_3_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_11221/3356513853.py:37 in forward, code: return torch.sigmoid(t1_strength - t2_strength)\n",
       "                    sub_24: \"f32[s77, 1]\" = torch.ops.aten.sub.Tensor(linear_3, linear_5);  linear_3 = linear_5 = None\n",
       "                    sigmoid: \"f32[s77, 1]\" = torch.ops.aten.sigmoid.default(sub_24);  sub_24 = None\n",
       "                    return (sigmoid,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_phi_0_weight: PARAMETER target='phi.0.weight'\n",
       "            p_phi_0_bias: PARAMETER target='phi.0.bias'\n",
       "            p_phi_3_weight: PARAMETER target='phi.3.weight'\n",
       "            p_phi_3_bias: PARAMETER target='phi.3.bias'\n",
       "            p_rho_0_weight: PARAMETER target='rho.0.weight'\n",
       "            p_rho_0_bias: PARAMETER target='rho.0.bias'\n",
       "            p_rho_3_weight: PARAMETER target='rho.3.weight'\n",
       "            p_rho_3_bias: PARAMETER target='rho.3.bias'\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            sigmoid: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {s77: VR[0, int_oo]}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T01:27:28.179410242Z",
     "start_time": "2026-01-14T01:27:28.134610859Z"
    }
   },
   "cell_type": "code",
   "source": "np.savez(f'scaler_params_{target_map}.npz', mean=scaler.mean_, scale=scaler.scale_)",
   "id": "b62b55f91b2e9620",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
